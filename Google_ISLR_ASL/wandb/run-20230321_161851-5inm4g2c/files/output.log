(94477, 5, 240) (94477, 5, 126) (94477, 5, 126)
(94477, 5, 492)
<class 'numpy.ndarray'> <class 'numpy.ndarray'>
[(94477, 5, 492), (94477,)]
None
[(77585, 5, 492), (8350, 5, 492), (8542, 5, 492)]
[(77585,), (8350,), (8542,)]
[[[ 4.66397226e-01  3.94536257e-01  1.50581989e-02 ...  2.16691364e-02
    8.60943925e-03  1.95792876e-02]
  [ 4.85990167e-01  3.97417128e-01  1.38089526e-02 ...  5.05504496e-02
    2.52848747e-03  1.26952035e-02]
  [ 5.04855275e-01  3.99389505e-01  3.33259255e-03 ...  5.11666276e-02
    1.80436969e-02  1.58287883e-02]
  [ 5.10454595e-01  3.97411972e-01  1.39432377e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 5.08072257e-01  3.97497416e-01  1.51141710e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]]
 [[ 5.18962860e-01  5.22190928e-01 -6.42546825e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 5.16603470e-01  5.21108866e-01 -7.76141370e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 5.12595236e-01  5.21464229e-01 -8.79468769e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 5.02227783e-01  5.22722960e-01 -1.03681562e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.91326243e-01  5.18015265e-01 -1.03542302e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]]
 [[ 4.43562537e-01  5.49001873e-01 -6.12042705e-03 ...  3.54431942e-02
    4.84067388e-03  4.26041661e-03]
  [ 4.53818083e-01  5.44819057e-01 -7.15515157e-03 ...  3.34666623e-03
    5.04173618e-03  3.40219704e-03]
  [ 4.58130926e-01  5.43311715e-01 -8.35081376e-03 ...  1.75950658e-02
    7.93376472e-03  1.02699511e-02]
  [ 4.61609334e-01  5.42545199e-01 -5.62995858e-03 ...  1.38998143e-02
    1.14851762e-02  1.49085103e-02]
  [ 4.59576845e-01  5.48978090e-01 -5.02116419e-03 ...  1.51854521e-02
    1.16312839e-02  7.09107472e-03]]
 ...
 [[ 4.79570329e-01  3.60501349e-01  2.73153954e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.78081405e-01  3.60182554e-01  1.74500351e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.77429450e-01  3.59742016e-01  1.35115231e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.77993906e-01  3.59843016e-01  1.92030752e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.77828175e-01  3.60610604e-01  1.95362605e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]]
 [[ 4.19481307e-01  4.98731226e-01  3.05532943e-03 ...  3.02328169e-03
    2.05419958e-02  1.65837258e-02]
  [ 4.30382252e-01  5.23031175e-01  3.67080397e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.32738692e-01  5.20131886e-01  3.82905733e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.26795274e-01  5.19963801e-01  1.07464723e-04 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 4.23161268e-01  5.18411696e-01  1.83282141e-03 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]]
 [[ 3.81504804e-01  3.75446707e-01 -1.60459671e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 3.83313090e-01  3.68086100e-01 -1.60362553e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 3.90624136e-01  3.69925410e-01 -1.48237087e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 3.92171055e-01  3.80757660e-01 -1.62861310e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]
  [ 3.99807066e-01  3.73458952e-01 -1.60872731e-02 ...  0.00000000e+00
    0.00000000e+00  0.00000000e+00]]]
train_loader: <torch.utils.data.dataloader.DataLoader object at 0x0000020B615EF8B0> 2425
True
GRU(
  (gru): GRU(492, 128, num_layers=2, batch_first=True)
  (fc): Linear(in_features=128, out_features=250, bias=True)
)
Epoch:0 > Train Loss: 4.2499, Train Acc: 0.1103
Epoch:0 > Val Loss: 3.7790, Val Acc: 0.1744
==================================================
Epoch:1 > Train Loss: 2.9593, Train Acc: 0.3075
Epoch:1 > Val Loss: 3.1985, Val Acc: 0.2771
==================================================
Epoch:2 > Train Loss: 2.4641, Train Acc: 0.4085
Epoch:2 > Val Loss: 2.9954, Val Acc: 0.3305
==================================================
Epoch:3 > Train Loss: 2.1862, Train Acc: 0.4723
Epoch:3 > Val Loss: 3.0240, Val Acc: 0.3303
==================================================
Epoch:4 > Train Loss: 2.0063, Train Acc: 0.5160
Epoch:4 > Val Loss: 2.8631, Val Acc: 0.3636
==================================================
Epoch:5 > Train Loss: 1.8872, Train Acc: 0.5462
Epoch:5 > Val Loss: 2.8521, Val Acc: 0.3684
==================================================
EarlyStopping counter: 1 out of 10
Epoch:6 > Train Loss: 1.8084, Train Acc: 0.5655
Epoch:6 > Val Loss: 2.8467, Val Acc: 0.3702
==================================================
EarlyStopping counter: 2 out of 10
Epoch:7 > Train Loss: 1.7547, Train Acc: 0.5800
Epoch:7 > Val Loss: 2.8385, Val Acc: 0.3723
==================================================
EarlyStopping counter: 3 out of 10
Epoch:8 > Train Loss: 1.7194, Train Acc: 0.5890
Epoch:8 > Val Loss: 2.7978, Val Acc: 0.3800
==================================================
EarlyStopping counter: 4 out of 10
Epoch:9 > Train Loss: 1.6946, Train Acc: 0.5959
Epoch:9 > Val Loss: 2.8279, Val Acc: 0.3749
==================================================
EarlyStopping counter: 5 out of 10
Epoch:10 > Train Loss: 1.6788, Train Acc: 0.6003
Epoch:10 > Val Loss: 2.8136, Val Acc: 0.3762
==================================================
EarlyStopping counter: 6 out of 10
Epoch:11 > Train Loss: 1.6678, Train Acc: 0.6035
Epoch:11 > Val Loss: 2.8257, Val Acc: 0.3747
==================================================
EarlyStopping counter: 7 out of 10
Epoch:12 > Train Loss: 1.6607, Train Acc: 0.6052
Epoch:12 > Val Loss: 2.8220, Val Acc: 0.3764
==================================================
EarlyStopping counter: 8 out of 10
Epoch:13 > Train Loss: 1.6556, Train Acc: 0.6068
Epoch:13 > Val Loss: 2.8269, Val Acc: 0.3744
==================================================
EarlyStopping counter: 9 out of 10
Epoch:14 > Train Loss: 1.6524, Train Acc: 0.6072
Epoch:14 > Val Loss: 2.8149, Val Acc: 0.3772
==================================================
Epoch:15 > Train Loss: 1.6501, Train Acc: 0.6080
Epoch:15 > Val Loss: 2.8224, Val Acc: 0.3752
==================================================
EarlyStopping counter: 1 out of 10
Epoch:16 > Train Loss: 1.6487, Train Acc: 0.6086
Epoch:16 > Val Loss: 2.8257, Val Acc: 0.3741
==================================================
EarlyStopping counter: 2 out of 10
Epoch:17 > Train Loss: 1.6478, Train Acc: 0.6086
Epoch:17 > Val Loss: 2.8242, Val Acc: 0.3746
==================================================
EarlyStopping counter: 3 out of 10
Epoch:18 > Train Loss: 1.6471, Train Acc: 0.6090
Epoch:18 > Val Loss: 2.8240, Val Acc: 0.3749
==================================================
EarlyStopping counter: 4 out of 10
Epoch:19 > Train Loss: 1.6469, Train Acc: 0.6090
Epoch:19 > Val Loss: 2.8255, Val Acc: 0.3750
==================================================
EarlyStopping counter: 5 out of 10
Epoch:20 > Train Loss: 1.6465, Train Acc: 0.6092
Epoch:20 > Val Loss: 2.8251, Val Acc: 0.3749
==================================================
EarlyStopping counter: 6 out of 10
Epoch:21 > Train Loss: 1.6461, Train Acc: 0.6092
Epoch:21 > Val Loss: 2.8252, Val Acc: 0.3752
==================================================
EarlyStopping counter: 7 out of 10
Epoch:22 > Train Loss: 1.6460, Train Acc: 0.6093
Epoch:22 > Val Loss: 2.8250, Val Acc: 0.3746
==================================================
EarlyStopping counter: 8 out of 10
Epoch:23 > Train Loss: 1.6460, Train Acc: 0.6092
Epoch:23 > Val Loss: 2.8250, Val Acc: 0.3746
==================================================
EarlyStopping counter: 9 out of 10
Epoch:24 > Train Loss: 1.6460, Train Acc: 0.6093
Epoch:24 > Val Loss: 2.8252, Val Acc: 0.3746
==================================================
EarlyStopping counter: 10 out of 10
Early Stopping!
best_val_loss: tensor(1.5582, device='cuda:0')
Learning Time: 368.04292392730713
test Loss: 2.5079, test Acc: 0.4240